# @package __global__
# Music Multiple - MusicGen Objective Evaluation Configuration
# Comprehensive objective metrics for MusicGen model assessment

# Setup for execute only on musiccaps for audio generation
# evaluation with objective metrics
# execute_only=evaluate

dataset:
  max_audio_duration: null
  # ensure the proper values are broadcasted here for evaluate
  evaluate:
    min_audio_duration: 1.  # some metrics requires a minimum audio length
    max_audio_duration: null  # all samples from musiccaps should be < 20s
    num_samples: null
    segment_duration: null
  generate:
    min_audio_duration: 1.
    max_audio_duration: null
    num_samples: 500

evaluate:
  metrics:
    fad: true
    kld: true
    text_consistency: true

# Music Multiple: Enhanced objective evaluation
music_multiple:
  evaluation_type: "comprehensive_objective"
  purpose: "quantitative_assessment_of_music_generation_quality"
  
  objective_metrics:
    frechet_audio_distance: 
      purpose: "audio_quality_and_diversity"
      genre_sensitivity: "moderate"
    kullback_leibler_divergence:
      purpose: "feature_distribution_alignment" 
      genre_sensitivity: "high"
    text_consistency:
      purpose: "semantic_alignment_with_text_description"
      multi_lingual_support: true
    
  # Music Multiple: Additional evaluation metrics
  enhanced_metrics:
    genre_classification_accuracy: true
    rhythm_pattern_fidelity: true
    instrument_recognition_score: true
    cultural_authenticity_score: true
    
  evaluation_datasets:
    primary: "musiccaps"
    secondary: ["audiocaps", "internal_music_datasets"]
    genre_specific: ["latin_music_benchmark", "multi_genre_eval_set"]
    
  quality_benchmarks:
    audio_quality: ">= 4.0/5.0 FAD"
    text_alignment: ">= 0.7 consistency"
    genre_accuracy: ">= 80% classification"
    cultural_authenticity: ">= 75%"